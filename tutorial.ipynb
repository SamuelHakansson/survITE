{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sksurv.metrics import concordance_index_ipcw\n",
    "\n",
    "from utils.utils import f_get_minibatch\n",
    "\n",
    "from models.survite import SurvITE\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipm_type      = 'wasserstein'\n",
    "\n",
    "weight        = False\n",
    "is_smoothing  = False\n",
    "is_treat      = True\n",
    "\n",
    "is_training   = True#True\n",
    "\n",
    "OUT_ITERATION = 5\n",
    "N_tr = 5000\n",
    "N_te = 5000\n",
    "\n",
    "if not weight:\n",
    "    weight_type = 'noweight'\n",
    "else:\n",
    "    weight_type  = '' \n",
    "\n",
    "\n",
    "if ipm_type == 'no_ipm':\n",
    "    beta       = 0.\n",
    "else:\n",
    "    beta   = 1e-3 #1e-3\n",
    "\n",
    "    \n",
    "if is_smoothing:\n",
    "    gamma  = 1e-3\n",
    "else:\n",
    "    gamma  = 0.\n",
    "\n",
    "\n",
    "lr_rate   = 1e-3\n",
    "mb_size   = 512\n",
    "\n",
    "keep_prob = 0.7\n",
    "\n",
    "seed           = 1234\n",
    "\n",
    "TMAX           = 30\n",
    "eval_times     = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "\n",
    "\n",
    "# results_mse_hzrd1 = np.zeros([OUT_ITERATION, TMAX+1])\n",
    "# results_mse_hzrd0 = np.zeros([OUT_ITERATION, TMAX+1])\n",
    "\n",
    "# results_mse_surv1 = np.zeros([OUT_ITERATION, TMAX+1])\n",
    "# results_mse_surv0 = np.zeros([OUT_ITERATION, TMAX+1])\n",
    "\n",
    "# results_hte_hzrd   = np.zeros([OUT_ITERATION, TMAX+1])\n",
    "# results_hte_surv   = np.zeros([OUT_ITERATION, TMAX+1])\n",
    "\n",
    "# results1 = np.zeros([OUT_ITERATION, len(eval_times)])\n",
    "# results2 = np.zeros([OUT_ITERATION, len(eval_times)])\n",
    "# results3 = np.zeros([OUT_ITERATION, len(eval_times)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed         = 1234\n",
    "modelname    = 'SurvITE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT OBSERVATIONAL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz  = np.load('./data/tr_data.npz')\n",
    "tr_x = npz['x']\n",
    "tr_a = npz['a']\n",
    "tr_t = npz['t']\n",
    "tr_y = npz['y']\n",
    "\n",
    "npz  = np.load('./data/te_data.npz')\n",
    "te_x = npz['x']\n",
    "te_a = npz['a']\n",
    "te_t = npz['t']\n",
    "te_y = npz['y']\n",
    "\n",
    "tr_y_structured = [(tr_y[i], tr_t[i]) for i in range(len(tr_y))]\n",
    "tr_y_structured = np.array(tr_y_structured, dtype=[('status', 'bool'),('time','<f8')])\n",
    "\n",
    "te_y_structured = [(te_y[i], te_t[i]) for i in range(len(te_y))]\n",
    "te_y_structured = np.array(te_y_structured, dtype=[('status', 'bool'),('time','<f8')])\n",
    "\n",
    "\n",
    "TMAX           = 30\n",
    "eval_times     = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "\n",
    "\n",
    "results_mse_hzrd1 = np.zeros([1, TMAX+1])\n",
    "results_mse_hzrd0 = np.zeros([1, TMAX+1])\n",
    "\n",
    "results_mse_surv1 = np.zeros([1, TMAX+1])\n",
    "results_mse_surv0 = np.zeros([1, TMAX+1])\n",
    "\n",
    "results_hte_hzrd   = np.zeros([1, TMAX+1])\n",
    "results_hte_surv   = np.zeros([1, TMAX+1])\n",
    "\n",
    "results1 = np.zeros([1, len(eval_times)])\n",
    "results2 = np.zeros([1, len(eval_times)])\n",
    "results3 = np.zeros([1, len(eval_times)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_Event   = 1\n",
    "\n",
    "z_dim       = 100\n",
    "x_dim       = np.shape(tr_x)[1]\n",
    "\n",
    "num_layers1  = 3\n",
    "h_dim1       = 100\n",
    "\n",
    "num_layers2  = 2\n",
    "h_dim2       = 100\n",
    "\n",
    "\n",
    "input_dims = {\n",
    "    'x_dim': x_dim,\n",
    "    'num_Event': num_Event,\n",
    "    't_max': TMAX+1\n",
    "}\n",
    "network_settings = {\n",
    "    'z_dim': z_dim,     \n",
    "\n",
    "    # Phi()\n",
    "    'h_dim1': h_dim1, \n",
    "    'num_layers1': num_layers1, \n",
    "\n",
    "    # Hypothesis()\n",
    "    'h_dim2': h_dim2, \n",
    "    'num_layers2': num_layers2,\n",
    "\n",
    "    'active_fn': tf.nn.elu,\n",
    "    'reg_scale': 0.,\n",
    "    'ipm_term' : ipm_type, \n",
    "    'is_treat' : is_treat,\n",
    "    'is_smoothing': is_smoothing\n",
    "}\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "model = SurvITE(sess, 'SurvITE', input_dims, network_settings)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver       = tf.train.Saver()\n",
    "\n",
    "savepath = './{}/surviTE/'.format(modelname)\n",
    "\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_treat:\n",
    "    tr_a = np.ones_like(tr_t)\n",
    "    te_a = np.ones_like(te_t)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tr_y = tr_y.reshape([-1,1])\n",
    "tr_t = tr_t.reshape([-1,1])\n",
    "tr_a = tr_a.reshape([-1,1])\n",
    "\n",
    "if is_treat:\n",
    "    tr_w  = np.ones([np.shape(tr_x)[0], TMAX+1, 2])\n",
    "else:\n",
    "    tr_w  = np.ones([np.shape(tr_x)[0], TMAX+1, 1])\n",
    "\n",
    "tr_x_,va_x, tr_y_,va_y, tr_t_,va_t, tr_a_,va_a, tr_w_,va_w = train_test_split(tr_x, tr_y, tr_t, tr_a, tr_w, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 20000\n",
    "\n",
    "avg_tr_loss_total = 0.\n",
    "avg_tr_loss       = 0.\n",
    "avg_tr_loss_ipm   = 0.\n",
    "\n",
    "avg_va_loss_total = 0.\n",
    "avg_va_loss       = 0.\n",
    "avg_va_loss_ipm   = 0.\n",
    "\n",
    "check_step        = 100\n",
    "\n",
    "min_loss          = 1e+8\n",
    "max_flag          = 20\n",
    "stop_flag         = 0\n",
    "\n",
    "if is_training:\n",
    "    for itr in range(iterations):    \n",
    "        if beta == 0.:\n",
    "            x_mb, y_mb, t_mb, a_mb = f_get_minibatch(mb_size, tr_x_, tr_y_, tr_t_, tr_a_)    \n",
    "            _, _, tmp_tr_loss          = model.train_baseline(x_mb, y_mb, t_mb, a_mb, lr_train_=lr_rate, k_prob_=keep_prob)\n",
    "            avg_tr_loss_total         += tmp_tr_loss/check_step\n",
    "            avg_tr_loss               += tmp_tr_loss/check_step\n",
    "\n",
    "            x_mb, y_mb, t_mb, a_mb = f_get_minibatch(min(mb_size, np.shape(va_x)[0]), va_x, va_y, va_t, va_a)    \n",
    "            tmp_va_loss                = model.get_loss_basline(x_mb, y_mb, t_mb, a_mb, k_prob_=keep_prob)\n",
    "            avg_va_loss_total         += tmp_va_loss/check_step\n",
    "            avg_va_loss               += tmp_va_loss/check_step\n",
    "\n",
    "        else:\n",
    "            x_mb, y_mb, t_mb, a_mb, w_mb = f_get_minibatch(mb_size, tr_x_, tr_y_, tr_t_, tr_a_, tr_w_)\n",
    "            _, _, tmp_tr_loss_total, tmp_tr_loss, tmp_tr_loss_ipm = model.train(x_mb, y_mb, t_mb, a_mb, w_mb, \n",
    "                                                                                beta_=beta, gamma_=gamma, \n",
    "                                                                                lr_train_=lr_rate, k_prob_=keep_prob)\n",
    "            avg_tr_loss_total         += tmp_tr_loss_total/check_step\n",
    "            avg_tr_loss               += tmp_tr_loss/check_step\n",
    "            avg_tr_loss_ipm           += tmp_tr_loss_ipm/check_step\n",
    "\n",
    "            x_mb, y_mb, t_mb, a_mb, w_mb = f_get_minibatch(min(mb_size, np.shape(va_x)[0]), va_x, va_y, va_t, va_a, va_w)    \n",
    "            tmp_va_loss_total, tmp_va_loss, tmp_va_loss_ipm      = model.get_loss(x_mb, y_mb, t_mb, a_mb, w_mb, \n",
    "                                                                                  beta_=beta, gamma_=gamma, \n",
    "                                                                                  k_prob_=1.0)\n",
    "            avg_va_loss_total         += tmp_va_loss_total/check_step\n",
    "            avg_va_loss               += tmp_va_loss/check_step\n",
    "            avg_va_loss_ipm           += tmp_va_loss_ipm/check_step\n",
    "\n",
    "        if (itr + 1)%check_step == 0:\n",
    "            stop_flag += 1\n",
    "\n",
    "            print(\n",
    "                \"ITR {:04d}  | TR: loss_T={:.3f} loss_S={:.3f} loss_IPM={:.3f} | loss_T={:.3f} loss_S={:.3f} loss_IPM={:.3f}\".format(\n",
    "                itr+1, avg_tr_loss_total, avg_tr_loss, avg_tr_loss_ipm, avg_va_loss_total, avg_va_loss, avg_va_loss_ipm)\n",
    "            )\n",
    "\n",
    "            if min_loss > avg_va_loss_total:\n",
    "                min_loss  = avg_va_loss_total\n",
    "                stop_flag = 0\n",
    "\n",
    "                saver.save(sess, savepath + 'model_{}{}'.format(ipm_type,weight_type))\n",
    "                print('model saved...')\n",
    "\n",
    "            else:\n",
    "                if stop_flag >= max_flag:\n",
    "                    break\n",
    "\n",
    "\n",
    "            avg_tr_loss_total = 0.\n",
    "            avg_tr_loss = 0.\n",
    "            avg_tr_loss_ipm = 0.\n",
    "\n",
    "            avg_va_loss_total = 0.\n",
    "            avg_va_loss = 0.\n",
    "            avg_va_loss_ipm = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore(sess, savepath + 'model_{}{}'.format(ipm_type,weight_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv1 = model.predict_survival_A1(te_x)\n",
    "surv0 = model.predict_survival_A0(te_x)\n",
    "\n",
    "hzrd1 = model.predict_hazard_A1(te_x)\n",
    "hzrd0 = model.predict_hazard_A0(te_x)\n",
    "\n",
    "hzrd = np.zeros_like(hzrd1)\n",
    "if is_treat:\n",
    "    hzrd[te_a == 0, :] = hzrd0[te_a == 0, :]\n",
    "hzrd[te_a == 1, :] = hzrd1[te_a == 1, :]\n",
    "\n",
    "surv = np.zeros_like(surv1)\n",
    "if is_treat:\n",
    "    surv[te_a == 0, :] = surv0[te_a == 0, :]\n",
    "surv[te_a == 1, :] = surv1[te_a == 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
